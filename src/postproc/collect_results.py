
#Standard library
import os
import os.path as osp

#Site packages
import pandas as pd

#Local
from folderstructure import *
import useful

def list_inputfiles(basename):
  """Return a list of all info.yaml files for the given basename.
  The list is generated by reading the directories."""
  basedir=osp.join(solnfolder,basename)
  assert osp.isdir(basedir), "Could not find base directory: %s"%basedir
  filelist=[]
  for content in os.listdir(basedir):
    dirname = osp.join(basedir,content)
    if osp.isdir(dirname):
      fpath=osp.join(dirname,'info.yaml')
      if osp.isfile(fpath):
        filelist.append(fpath)
  return filelist

def get_columns(d):
  """Return list of all keys where the values are integers, floats, or strings,
  and call recursively on any value that has its own 'items' attribute."""
  cols=[]
  for k,v in d.items():
    if type(v)==int or type(v)==float or type(v)==str:
      cols.append(k)
    elif hasattr(v,'items'):
      newcols=get_columns(v)
      cols.extend([c for c in newcols if c not in cols])
  return cols

def get_all_columns(dlist):
  """Return the superset of columns for each d in dlist"""
  columns=get_columns(dlist[0])
  for d in dlist[1:]:
    newcols=get_columns(d)
    for c in newcols:
      if not c in columns:
        c.append(columns)
  return columns

def flatdict(d,cols):
  """Flatten a potentially nested dictionary so it can be added to a DataFrame with the specified columns."""
  fd={}
  for k,v in d.items():
    if k in cols and (type(v)==int or type(v)==float or type(v)==str):
      fd[k]=v
    elif hasattr(v,'items'):
      for newk, newv in flatdict(v,cols).items():
        if newk in fd.keys():
          assert newv==fd[newk], "Unequal assignments to %s: previously had %s, but %s wants to change it to %s"%(str(newk),str(fd[newk]),str(k),str(newv))
        else:
          fd[newk]=newv
  return fd

def dicts_to_dataframe(alldicts):
  """Create a pandas dataframe from an iterable of dictionaries.
  Arguments:
    alldicts = iterable of dictionaries
  Return value:
    df = pandas dataframe
  For each dictionary:
    Anything that is a number or string is added directly.
    Anything that is a dictionary has its items treated the same way.
      (More specifically, anything that has an 'items' attribute.)
    Everything else is ignored, including any sequences."""
  #Get the list of columns for the dataframe, and make it works for all the dictionaries
  columns=get_all_columns(alldicts)
  #Set up dataframe with required columns
  df=pd.DataFrame(columns=columns)
  #Add the data to the dataframe
  for d in alldicts:
    fd=flatdict(d,columns)
    df=df.append(fd,ignore_index=True)
  return df
  
def do_collection(inputfiles,outfpath):
  """Generate a pandas dataframe from the specified input files, written to the output file
  Arguments:
    inputfiles = iterable of input files (yaml format) to read.
      This should be the complete paths, as strings.
    outfpath = path to the output file (pickle format), as a string.
  No return value.
  Output file is generated.
  """
  alldicts = [useful.readyaml(fp) for fp in inputfiles]
  df = dicts_to_dataframe(alldicts)
  df.to_pickle(outfpath)
  return

#-------------------------------------------------------------------------------
def read_all_dicts(rundict):
  #Dictionary of all meshes, by name
  allmeshes={}
  for doc in useful.readyaml_multidoc(rundict['meshparams']):
    allmeshes[doc['meshname']]=doc
  #Dictionary of all models, by name
  allmodels={}
  for doc in useful.readyaml_multidoc(rundict['modelparams']):
    allmodels[doc['modelname']]=doc
  return allmeshes, allmodels

def list_result_files(rundict):
  allmeshes, allmodels=read_all_dicts(rundict)
  infiles=[osp.join(solnfolder,mname,'results.yaml') for mname in allmodels.keys()]
  return infiles

def gen_dataframe(rundict):
  infiles=list_result_files(rundict)
  alldicts=[]
  for infpath in infiles:
    alldicts.append(useful.readyaml(infpath))
  df = pd.DataFrame(alldicts)
  return df


def collectall(rundict):
  outfpath=osp.join(solnfolder,rundict['master']+'.pkl.gz')
  df = gen_dataframe(rundict)
  df.to_pickle(outfpath)